{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b949d068-26e5-4f87-be02-9dea5ce05c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Данные успешно загружены и сохранены в sagriculture_loans_final_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from calendar import monthrange\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "#  Настройки \n",
    "base_url = \"https://www.nationalbank.kz\"\n",
    "rubric_urls = [\n",
    "    \"https://www.nationalbank.kz/ru/news/banking-sector-loans-to-economy-analytics/rubrics/1907\",\n",
    "    \"https://www.nationalbank.kz/ru/news/banking-sector-loans-to-economy-analytics/rubrics/1985\",\n",
    "    \"https://www.nationalbank.kz/ru/news/banking-sector-loans-to-economy-analytics/rubrics/2204\",\n",
    "    \"https://www.nationalbank.kz/ru/news/banking-sector-loans-to-economy-analytics/rubrics/2319\",\n",
    "]\n",
    "save_folder = Path(\"./nbkr_downloads\")\n",
    "save_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "include_keyword = \"Кредиты банковского сектора субъектам предпринимательства\"\n",
    "exclude_keywords = [\"по видам экономической деятельности\", \"по расширенной классификации\"]\n",
    "\n",
    "TYPE_MAPPING = {\n",
    "    \"субъектам малого предпринимательства в национальной валюте\": 2,\n",
    "    \"субъектам малого предпринимательства в иностранной валюте\": 3,\n",
    "    \"субъектам среднего предпринимательства в национальной валюте\": 4,\n",
    "    \"субъектам среднего предпринимательства в иностранной валюте\": 5,\n",
    "    \"субъектам крупного предпринимательства в национальной валюте\": 6,\n",
    "    \"субъектам крупного предпринимательства в иностранной валюте\": 7,\n",
    "}\n",
    "REVERSE_MAPPING = {v: k for k, v in TYPE_MAPPING.items()}\n",
    "month_map = {\n",
    "    \"январь\": 1, \"февраль\": 2, \"март\": 3, \"апрель\": 4, \"май\": 5, \"июнь\": 6,\n",
    "    \"июль\": 7, \"август\": 8, \"сентябрь\": 9, \"октябрь\": 10, \"ноябрь\": 11, \"декабрь\": 12\n",
    "}\n",
    "LOAD_DATE = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "PACKAGE_ID = 1\n",
    "\n",
    "def extract_target_files(html):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    file_entries = []\n",
    "    for item in soup.select(\"div.posts-files__item\"):\n",
    "        title_tag = item.select_one(\"div.posts-files__title a\")\n",
    "        if not title_tag:\n",
    "            continue\n",
    "        title_text = title_tag.text.strip()\n",
    "        href = title_tag.get(\"href\", \"\")\n",
    "        if include_keyword in title_text and not any(bad in title_text for bad in exclude_keywords):\n",
    "            full_url = base_url + href\n",
    "            file_id = href.split(\"/\")[-1]\n",
    "            file_name = f\"{file_id}.xlsx\"\n",
    "            file_entries.append((title_text, full_url, file_name))\n",
    "    return file_entries\n",
    "\n",
    "# Основной процесс\n",
    "all_records = []\n",
    "\n",
    "for url in rubric_urls:\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    for title, file_url, file_name in extract_target_files(response.text):\n",
    "        file_path = save_folder / file_name\n",
    "        try:\n",
    "            if not file_path.exists():\n",
    "                file_data = requests.get(file_url)\n",
    "                file_data.raise_for_status()\n",
    "                with open(file_path, \"wb\") as f:\n",
    "                    f.write(file_data.content)\n",
    "\n",
    "            xls = pd.ExcelFile(file_path, engine=\"openpyxl\")\n",
    "            df = xls.parse(\"Выдано\", header=None)\n",
    "\n",
    "            dates = df.iloc[4].ffill()\n",
    "            categories = df.iloc[5].ffill()\n",
    "            currencies = df.iloc[6].ffill()\n",
    "\n",
    "            full_headers = []\n",
    "            for d, c, v in zip(dates, categories, currencies):\n",
    "                if pd.isna(d) or pd.isna(c) or pd.isna(v):\n",
    "                    full_headers.append(None)\n",
    "                else:\n",
    "                    full_headers.append(f\"{d.strip()} | {c.strip()} {v.strip()}\")\n",
    "\n",
    "            agri_row_idx = df[df[0].astype(str).str.contains(\"сельское\", case=False, na=False)].index[0]\n",
    "            agri_values = df.iloc[agri_row_idx]\n",
    "\n",
    "            period_cat_map = {}\n",
    "            for i, val in enumerate(agri_values[1:], start=1):\n",
    "                header = full_headers[i]\n",
    "                if not header:\n",
    "                    continue\n",
    "                try:\n",
    "                    period_raw, cat_full = header.split(\"|\")\n",
    "                    cat_full = cat_full.strip()\n",
    "                    match = re.search(r\"за\\s(\\w+)\\s(\\d{4})\", period_raw.strip())\n",
    "                    if not match:\n",
    "                        continue\n",
    "                    month_name, year = match.groups()\n",
    "                    month = month_map.get(month_name.lower())\n",
    "                    if not month:\n",
    "                        continue\n",
    "                    last_day = monthrange(int(year), month)[1]\n",
    "                    period = f\"{year}-{month:02d}-{last_day}\"\n",
    "                    TYPE = TYPE_MAPPING.get(cat_full)\n",
    "                    if not TYPE:\n",
    "                        continue\n",
    "                    value = str(val).replace(\" \", \"\").replace(\",\", \".\")\n",
    "                    value = float(value) if value and value != \"nan\" else 0.0\n",
    "                    period_cat_map[(period, TYPE)] = {\n",
    "                        \"LOAD_DATE\": LOAD_DATE,\n",
    "                        \"PACKAGE_ID\": PACKAGE_ID,\n",
    "                        \"TYPE\": TYPE,\n",
    "                        \"TYPE_DESCRIPTION\": cat_full,\n",
    "                        \"AGRICULTURAL_INDUSTRY\": round(value, 2),\n",
    "                        \"PERIOD\": period,\n",
    "                        \"PERIOD_TYPE\": \"month\"\n",
    "                    }\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "            grouped = {}\n",
    "            for (period, TYPE), data in period_cat_map.items():\n",
    "                grouped.setdefault(period, []).append(data)\n",
    "\n",
    "            for period, records in grouped.items():\n",
    "                total = sum(r[\"AGRICULTURAL_INDUSTRY\"] for r in records)\n",
    "                records.append({\n",
    "                    \"LOAD_DATE\": LOAD_DATE,\n",
    "                    \"PACKAGE_ID\": PACKAGE_ID,\n",
    "                    \"TYPE\": 1,\n",
    "                    \"TYPE_DESCRIPTION\": \"Всего\",\n",
    "                    \"AGRICULTURAL_INDUSTRY\": round(total, 2),\n",
    "                    \"PERIOD\": period,\n",
    "                    \"PERIOD_TYPE\": \"month\"\n",
    "                })\n",
    "                all_records.extend(records)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "df_result = pd.DataFrame(all_records)\n",
    "df_result[\"PERIOD\"] = pd.to_datetime(df_result[\"PERIOD\"])\n",
    "df_result[\"YEAR\"] = df_result[\"PERIOD\"].dt.year\n",
    "\n",
    "df_yearly = (\n",
    "    df_result.groupby([\"YEAR\", \"TYPE\", \"TYPE_DESCRIPTION\"])\n",
    "    .agg({\"AGRICULTURAL_INDUSTRY\": \"sum\"})\n",
    "    .reset_index()\n",
    ")\n",
    "df_yearly[\"PERIOD\"] = pd.to_datetime(df_yearly[\"YEAR\"].astype(str) + \"-12-31\")\n",
    "df_yearly[\"PERIOD_TYPE\"] = \"year\"\n",
    "df_yearly[\"LOAD_DATE\"] = LOAD_DATE\n",
    "df_yearly[\"PACKAGE_ID\"] = PACKAGE_ID\n",
    "\n",
    "df_final = pd.concat([\n",
    "    df_result[[\n",
    "        \"LOAD_DATE\", \"PACKAGE_ID\", \"TYPE\", \"TYPE_DESCRIPTION\",\n",
    "        \"AGRICULTURAL_INDUSTRY\", \"PERIOD\", \"PERIOD_TYPE\"\n",
    "    ]],\n",
    "    df_yearly[[\n",
    "        \"LOAD_DATE\", \"PACKAGE_ID\", \"TYPE\", \"TYPE_DESCRIPTION\",\n",
    "        \"AGRICULTURAL_INDUSTRY\", \"PERIOD\", \"PERIOD_TYPE\"\n",
    "    ]]\n",
    "], ignore_index=True)\n",
    "\n",
    "df_final.drop_duplicates(subset=[\"PERIOD\", \"TYPE\", \"PERIOD_TYPE\"], inplace=True)\n",
    "df_final.to_csv(\"sagriculture_loans_final_clean.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Данные успешно загружены и сохранены в sagriculture_loans_final_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f40fa0fc-7345-428d-857f-47351916722e",
   "metadata": {},
   "outputs": [
    {
     "ename": "InsufficientResources",
     "evalue": "Severity: ERROR, Message: Insufficient resources to execute plan on pool general [Timedout waiting for resource request: Request exceeds limits: Memory(KB) Exceeded: Requested = 22026, Free = 0 (Limit = 34410400, Used = 34923502) (queueing threshold)], Sqlstate: 53000, Routine: Exec_compilePlan, File: /data/jenkins/workspace/RE-ReleaseBuilds/RE-Miner/server/vertica/Dist/PlanExecCoordinator.cpp, Line: 3033, Error Code: 3587, SQL: 'SELECT MAX(PACKAGE_ID) FROM SANDBOX.D_LENDING_APK_BVU_RK'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInsufficientResources\u001B[0m                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[129], line 164\u001B[0m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m vertica_python\u001B[38;5;241m.\u001B[39mconnect(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconn_info) \u001B[38;5;28;01mas\u001B[39;00m connection:\n\u001B[1;32m    163\u001B[0m     cur \u001B[38;5;241m=\u001B[39m connection\u001B[38;5;241m.\u001B[39mcursor()\n\u001B[0;32m--> 164\u001B[0m     \u001B[43mcur\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSELECT MAX(PACKAGE_ID) FROM \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mtarget_table\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    165\u001B[0m     max_package_id \u001B[38;5;241m=\u001B[39m cur\u001B[38;5;241m.\u001B[39mfetchone()[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    166\u001B[0m     new_package_id \u001B[38;5;241m=\u001B[39m max_package_id \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/Desktop/work/myenv/lib/python3.8/site-packages/vertica_python/vertica/cursor.py:187\u001B[0m, in \u001B[0;36mCursor.handle_ctrl_c.<locals>.wrap\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrap\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    186\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 187\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[1;32m    189\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconnection\u001B[38;5;241m.\u001B[39mcancel()\n",
      "File \u001B[0;32m~/Desktop/work/myenv/lib/python3.8/site-packages/vertica_python/vertica/cursor.py:265\u001B[0m, in \u001B[0;36mCursor.execute\u001B[0;34m(self, operation, parameters, use_prepared_statements, copy_stdin, buffer_size)\u001B[0m\n\u001B[1;32m    263\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m parameters:\n\u001B[1;32m    264\u001B[0m         operation \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mformat_operation_with_parameters(operation, parameters)\n\u001B[0;32m--> 265\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_simple_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43moperation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    267\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/Desktop/work/myenv/lib/python3.8/site-packages/vertica_python/vertica/cursor.py:788\u001B[0m, in \u001B[0;36mCursor._execute_simple_query\u001B[0;34m(self, query)\u001B[0m\n\u001B[1;32m    786\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_message \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconnection\u001B[38;5;241m.\u001B[39mread_message()\n\u001B[1;32m    787\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_message, messages\u001B[38;5;241m.\u001B[39mErrorResponse):\n\u001B[0;32m--> 788\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mQueryError\u001B[38;5;241m.\u001B[39mfrom_error_response(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_message, query)\n\u001B[1;32m    789\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_message, messages\u001B[38;5;241m.\u001B[39mVerifyFiles):\n\u001B[1;32m    790\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_copy_local_protocol()\n",
      "\u001B[0;31mInsufficientResources\u001B[0m: Severity: ERROR, Message: Insufficient resources to execute plan on pool general [Timedout waiting for resource request: Request exceeds limits: Memory(KB) Exceeded: Requested = 22026, Free = 0 (Limit = 34410400, Used = 34923502) (queueing threshold)], Sqlstate: 53000, Routine: Exec_compilePlan, File: /data/jenkins/workspace/RE-ReleaseBuilds/RE-Miner/server/vertica/Dist/PlanExecCoordinator.cpp, Line: 3033, Error Code: 3587, SQL: 'SELECT MAX(PACKAGE_ID) FROM SANDBOX.D_LENDING_APK_BVU_RK'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from calendar import monthrange\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import vertica_python\n",
    "\n",
    "# Настройки \n",
    "base_url = \"https://www.nationalbank.kz\"\n",
    "rubric_urls = [\n",
    "    \"https://www.nationalbank.kz/ru/news/banking-sector-loans-to-economy-analytics/rubrics/1907\",\n",
    "    \"https://www.nationalbank.kz/ru/news/banking-sector-loans-to-economy-analytics/rubrics/1985\",\n",
    "    \"https://www.nationalbank.kz/ru/news/banking-sector-loans-to-economy-analytics/rubrics/2204\",\n",
    "    \"https://www.nationalbank.kz/ru/news/banking-sector-loans-to-economy-analytics/rubrics/2319\",\n",
    "]\n",
    "save_folder = Path(\"./nbkr_downloads\")\n",
    "save_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "include_keyword = \"Кредиты банковского сектора субъектам предпринимательства\"\n",
    "exclude_keywords = [\"по видам экономической деятельности\", \"по расширенной классификации\"]\n",
    "\n",
    "TYPE_MAPPING = {\n",
    "    \"субъектам малого предпринимательства в национальной валюте\": 2,\n",
    "    \"субъектам малого предпринимательства в иностранной валюте\": 3,\n",
    "    \"субъектам среднего предпринимательства в национальной валюте\": 4,\n",
    "    \"субъектам среднего предпринимательства в иностранной валюте\": 5,\n",
    "    \"субъектам крупного предпринимательства в национальной валюте\": 6,\n",
    "    \"субъектам крупного предпринимательства в иностранной валюте\": 7,\n",
    "}\n",
    "REVERSE_MAPPING = {v: k for k, v in TYPE_MAPPING.items()}\n",
    "month_map = {\n",
    "    \"январь\": 1, \"февраль\": 2, \"март\": 3, \"апрель\": 4, \"май\": 5, \"июнь\": 6,\n",
    "    \"июль\": 7, \"август\": 8, \"сентябрь\": 9, \"октябрь\": 10, \"ноябрь\": 11, \"декабрь\": 12\n",
    "}\n",
    "LOAD_DATE = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "conn_info = {\n",
    "    'host': '10.7.7.231',\n",
    "    'port': 5433,\n",
    "    'user': '',\n",
    "    'password': '',\n",
    "    'database': '',\n",
    "    'autocommit': True,\n",
    "    'tlsmode': 'disable'\n",
    "}\n",
    "\n",
    "target_table = 'SANDBOX.D_LENDING_APK_BVU_RK'\n",
    "\n",
    "\n",
    "def extract_target_files(html):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    file_entries = []\n",
    "    for item in soup.select(\"div.posts-files__item\"):\n",
    "        title_tag = item.select_one(\"div.posts-files__title a\")\n",
    "        if not title_tag:\n",
    "            continue\n",
    "        title_text = title_tag.text.strip()\n",
    "        href = title_tag.get(\"href\", \"\")\n",
    "        if include_keyword in title_text and not any(bad in title_text for bad in exclude_keywords):\n",
    "            full_url = base_url + href\n",
    "            file_id = href.split(\"/\")[-1]\n",
    "            file_name = f\"{file_id}.xlsx\"\n",
    "            file_entries.append((title_text, full_url, file_name))\n",
    "    return file_entries\n",
    "\n",
    "all_records = []\n",
    "for url in rubric_urls:\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    for title, file_url, file_name in extract_target_files(response.text):\n",
    "        file_path = save_folder / file_name\n",
    "        try:\n",
    "            if not file_path.exists():\n",
    "                file_data = requests.get(file_url)\n",
    "                file_data.raise_for_status()\n",
    "                with open(file_path, \"wb\") as f:\n",
    "                    f.write(file_data.content)\n",
    "\n",
    "            xls = pd.ExcelFile(file_path, engine=\"openpyxl\")\n",
    "            df = xls.parse(\"Выдано\", header=None)\n",
    "\n",
    "            dates = df.iloc[4].ffill()\n",
    "            categories = df.iloc[5].ffill()\n",
    "            currencies = df.iloc[6].ffill()\n",
    "\n",
    "            full_headers = []\n",
    "            for d, c, v in zip(dates, categories, currencies):\n",
    "                if pd.isna(d) or pd.isna(c) or pd.isna(v):\n",
    "                    full_headers.append(None)\n",
    "                else:\n",
    "                    full_headers.append(f\"{str(d).strip()} | {str(c).strip()} {str(v).strip()}\")\n",
    "\n",
    "            agri_row_idx = df[df[0].astype(str).str.contains(\"сельское\", case=False, na=False)].index[0]\n",
    "            agri_values = df.iloc[agri_row_idx]\n",
    "\n",
    "            period_cat_map = {}\n",
    "            for i, val in enumerate(agri_values[1:], start=1):\n",
    "                header = full_headers[i]\n",
    "                if not header:\n",
    "                    continue\n",
    "                try:\n",
    "                    period_raw, cat_full = header.split(\"|\")\n",
    "                    cat_full = cat_full.strip()\n",
    "                    match = re.search(r\"за\\s(\\w+)\\s(\\d{4})\", period_raw.strip())\n",
    "                    if not match:\n",
    "                        continue\n",
    "                    month_name, year = match.groups()\n",
    "                    month = month_map.get(month_name.lower())\n",
    "                    if not month:\n",
    "                        continue\n",
    "                    last_day = monthrange(int(year), month)[1]\n",
    "                    period = f\"{year}-{month:02d}-{last_day}\"\n",
    "                    TYPE = TYPE_MAPPING.get(cat_full)\n",
    "                    if not TYPE:\n",
    "                        continue\n",
    "                    value = str(val).replace(\" \", \"\").replace(\",\", \".\")\n",
    "                    value = float(value) if value and value != \"nan\" else 0.0\n",
    "                    period_cat_map[(period, TYPE)] = {\n",
    "                        \"LOAD_DATE\": LOAD_DATE,\n",
    "                        \"TYPE\": TYPE,\n",
    "                        \"TYPE_DESCRIPTION\": cat_full,\n",
    "                        \"AGRICULTURAL_INDUSTRY\": round(value, 2),\n",
    "                        \"PERIOD\": period,\n",
    "                        \"PERIOD_TYPE\": \"month\"\n",
    "                    }\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "            grouped = {}\n",
    "            for (period, TYPE), data in period_cat_map.items():\n",
    "                grouped.setdefault(period, []).append(data)\n",
    "\n",
    "            for period, records in grouped.items():\n",
    "                total = sum(r[\"AGRICULTURAL_INDUSTRY\"] for r in records)\n",
    "                records.append({\n",
    "                    \"LOAD_DATE\": LOAD_DATE,\n",
    "                    \"TYPE\": 1,\n",
    "                    \"TYPE_DESCRIPTION\": \"Всего\",\n",
    "                    \"AGRICULTURAL_INDUSTRY\": round(total, 2),\n",
    "                    \"PERIOD\": period,\n",
    "                    \"PERIOD_TYPE\": \"month\"\n",
    "                })\n",
    "                all_records.extend(records)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "# Обработка\n",
    "if not all_records:\n",
    "    raise ValueError(\"Нет данных для обработки: all_records пуст.\")\n",
    "\n",
    "df_result = pd.DataFrame(all_records)\n",
    "df_result[\"PERIOD\"] = pd.to_datetime(df_result[\"PERIOD\"])\n",
    "df_result[\"YEAR\"] = df_result[\"PERIOD\"].dt.year\n",
    "\n",
    "with vertica_python.connect(**conn_info) as connection:\n",
    "    cur = connection.cursor()\n",
    "    cur.execute(f\"SELECT MAX(PACKAGE_ID) FROM {target_table}\")\n",
    "    max_package_id = cur.fetchone()[0] or 0\n",
    "    new_package_id = max_package_id + 1\n",
    "    df_result[\"PACKAGE_ID\"] = new_package_id\n",
    "\n",
    "    df_yearly = (\n",
    "        df_result.groupby([\"YEAR\", \"TYPE\", \"TYPE_DESCRIPTION\"])\n",
    "        .agg({\"AGRICULTURAL_INDUSTRY\": \"sum\"})\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_yearly[\"PERIOD\"] = pd.to_datetime(df_yearly[\"YEAR\"].astype(str) + \"-12-31\")\n",
    "    df_yearly[\"PERIOD_TYPE\"] = \"year\"\n",
    "    df_yearly[\"LOAD_DATE\"] = LOAD_DATE\n",
    "    df_yearly[\"PACKAGE_ID\"] = new_package_id\n",
    "\n",
    "    df_final = pd.concat([\n",
    "        df_result[[\n",
    "            \"LOAD_DATE\", \"PACKAGE_ID\", \"TYPE\", \"TYPE_DESCRIPTION\",\n",
    "            \"AGRICULTURAL_INDUSTRY\", \"PERIOD\", \"PERIOD_TYPE\"\n",
    "        ]],\n",
    "        df_yearly[[\n",
    "            \"LOAD_DATE\", \"PACKAGE_ID\", \"TYPE\", \"TYPE_DESCRIPTION\",\n",
    "            \"AGRICULTURAL_INDUSTRY\", \"PERIOD\", \"PERIOD_TYPE\"\n",
    "        ]]\n",
    "    ], ignore_index=True)\n",
    "\n",
    "    df_final.drop_duplicates(subset=[\"PERIOD\", \"TYPE\", \"PERIOD_TYPE\"], inplace=True)\n",
    "\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO {target_table} (\n",
    "            LOAD_DATE, PACKAGE_ID, TYPE, TYPE_DESCRIPTION,\n",
    "            AGRICULTURAL_INDUSTRY, PERIOD, PERIOD_TYPE\n",
    "        ) VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "\n",
    "    values = [\n",
    "        (\n",
    "            row['LOAD_DATE'], row['PACKAGE_ID'], row['TYPE'], row['TYPE_DESCRIPTION'],\n",
    "            row['AGRICULTURAL_INDUSTRY'], row['PERIOD'], row['PERIOD_TYPE']\n",
    "        )\n",
    "        for _, row in df_final.iterrows()\n",
    "    ]\n",
    "\n",
    "    cur.executemany(insert_query, values)\n",
    "\n",
    "print(f\"Данные успешно загружены в Vertica с PACKAGE_ID = {new_package_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b0b07-391f-4622-8fdf-e18c216e0400",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
